{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4ff2e5",
   "metadata": {},
   "source": [
    "## Part 1 - How it's done\n",
    "\n",
    "In this part I will demonstrate how to train a model on existing data by loading the dataset, splitting it into training and testing sets, create a decision tree classifier, train the model on the training set, make predictions on the testing set, and then evaluate the performance of the model using metrics such as accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b900ca",
   "metadata": {},
   "source": [
    "### 1. Import the required libraries\n",
    "\n",
    "In this code, I import the necessary libraries and modules to work with machine learning classification tasks using a decision tree classifier. I use the scikit-learn library, which is a popular choice for machine learning in Python.\n",
    "\n",
    "Firstly, I import the `load_iris` function from the `sklearn.datasets module`. This function allows me to load the Iris dataset, which is commonly used for classification tasks.\n",
    "\n",
    "Next, I import the `train_test_split` function from the `sklearn.model_selection module`. This function helps me split the dataset into training and testing subsets, ensuring that I can evaluate the performance of my classifier accurately.\n",
    "\n",
    "I also import the `DecisionTreeClassifier` class from the `sklearn.tree` module. This class provides the functionality to create and train a decision tree classifier, which is a powerful algorithm for classification tasks.\n",
    "\n",
    "To assess the performance of my classifier, I import several evaluation metrics from the `sklearn.metrics` module. These metrics include `accuracy_score`, `precision_score`, `recall_score`, and `f1_score`, which will help me measure the effectiveness of my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d93909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761d7d0",
   "metadata": {},
   "source": [
    "### 2. Load or generate the data that you want to use to train the model and split it into training and testing sets\n",
    "\n",
    "\n",
    "In this code, I load the Iris dataset, which is a well-known dataset frequently used in machine learning. The dataset contains measurements of different iris flowers.\n",
    "\n",
    "To load the dataset, I assign the `load_iris()` function to the variable `iris`. This function is part of the `scikit-learn` library and allows me to load the Iris dataset conveniently.\n",
    "\n",
    "Next, I extract the input features from the dataset and assign them to the variable `X`. These features include the measurements of the iris flowers, such as the length and width of the sepals and petals.\n",
    "\n",
    "Similarly, I extract the target labels from the dataset and assign them to the variable `y`. These labels represent the different species of iris flowers that we want to classify.\n",
    "\n",
    "By loading the dataset and separating the input features (`X`) and target labels (`y`), I am ready to explore and apply machine learning algorithms to classify the iris flowers based on their measurements. Let's continue our learning journey!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf444075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad4770a",
   "metadata": {},
   "source": [
    "### 3. Split data into training and testing sets\n",
    "\n",
    "In this code, I split the dataset into training and testing sets. This step is crucial to evaluate the performance of our machine learning model accurately.\n",
    "\n",
    "To split the dataset, I use the `train_test_split` function from the `scikit-learn` library. This function takes the input features (`X`) and target labels (`y`) as input and splits them into four separate subsets: `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "\n",
    "The test_size parameter is set to 0.2, which means that 20% of the data will be reserved for testing, while 80% will be used for training. Adjusting the `test_size` parameter allows us to control the size of the testing set.\n",
    "\n",
    "Additionally, I set the random_state parameter to 12. This ensures that the data is split in a consistent manner, meaning that every time I run the code, the same split will be generated. This is helpful for reproducibility and comparing results.\n",
    "\n",
    "By splitting the dataset into training and testing sets, we can train our machine learning model on the training data and then evaluate its performance on the unseen testing data. This helps us understand how well our model generalizes to new, unseen samples. Let's move forward and continue our machine learning journey!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f46be8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1ceae",
   "metadata": {},
   "source": [
    "### 4. Create an instance of the DecisionTreeRegressor class and fit the model to the training data\n",
    "\n",
    "In this code, I create a decision tree classifier and train it using the training set.\n",
    "\n",
    "To create the decision tree classifier, I instantiate an object of the `DecisionTreeClassifier` class from the `scikit-learn` library. This classifier is a powerful algorithm that can learn decision rules from the training data to make predictions.\n",
    "\n",
    "Next, I train the decision tree classifier using the `fit` method. I provide the training data (`X_train`) and the corresponding target labels (`y_train`) as input to the fit method. This allows the classifier to learn patterns and relationships between the input features and the target labels in the training set.\n",
    "\n",
    "By training the decision tree classifier, we enable it to make predictions based on the learned patterns. The model will now be able to classify new, unseen instances based on the features it has learned during the training phase.\n",
    "\n",
    "Now that our decision tree classifier is trained and ready, we can move on to the next step, which is evaluating its performance on the testing set. Let's continue exploring and analyzing our machine learning model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f0f409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c0e161",
   "metadata": {},
   "source": [
    "### 5. Make predictions on the testing set\n",
    "\n",
    "In this code, I use the trained decision tree classifier to make predictions on the testing set.\n",
    "\n",
    "After training the decision tree classifier, I apply it to the testing data using the predict method. The predict method takes the testing data (`X_test`) as input and returns the predicted labels for these instances.\n",
    "\n",
    "I store the predicted labels in the variable `y_pred`. These predicted labels represent the model's predictions for the corresponding instances in the testing set.\n",
    "\n",
    "By making predictions on the testing set, we can evaluate how well our trained model performs on unseen data. This step allows us to assess the model's ability to generalize and make accurate predictions on instances it has not encountered during the training phase.\n",
    "\n",
    "Now that we have obtained the predictions, we can proceed to evaluate the performance of our decision tree classifier using various evaluation metrics. Let's continue our analysis and see how well our model has performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5283bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06d5c2",
   "metadata": {},
   "source": [
    "### 6. Evaluate the performance of the model using accuracy, precision, recall, and F1 score\n",
    "\n",
    "In this code, I calculate various evaluation metrics, such as accuracy, precision, recall, and F1 score, to assess the performance of our trained decision tree classifier on the testing set.\n",
    "\n",
    "First, I use the `accuracy_score` function from the `scikit-learn` library to calculate the accuracy of our model's predictions. The `accuracy_score` function takes the true labels (`y_test`) and the predicted labels (`y_pred`) as input and returns the accuracy, which is the proportion of correct predictions.\n",
    "\n",
    "Next, I calculate the precision, recall, and F1 score using the `precision_score`, `recall_score`, and `f1_score` functions, respectively. These metrics provide additional insights into the performance of our model. The `average='weighted'` parameter ensures that we calculate these metrics by considering the weighted average across all classes, taking into account the support for each class.\n",
    "\n",
    "After calculating the metrics, I print them using the `print` function. This allows us to see the values of accuracy, precision, recall, and F1 score, which provide a comprehensive overview of the performance of our decision tree classifier.\n",
    "\n",
    "By evaluating these metrics, we can assess how well our model has performed in terms of correctly classifying the instances in the testing set. This analysis helps us understand the strengths and weaknesses of our trained model and guides us in making further improvements.\n",
    "\n",
    "Keep up the great work! Now you have a deeper understanding of how to evaluate the performance of a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5f59d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n",
      "Precision: 0.9700000000000001\n",
      "Recall: 0.9666666666666667\n",
      "F1 Score: 0.9665634674922601\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics such as accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ab5a08",
   "metadata": {},
   "source": [
    "## 2. Your turn\n",
    "\n",
    "Welcome to the next step of your machine learning journey! In this assignment, you will have the opportunity to work with the Red Wine Quality dataset from Kaggle. This dataset contains various chemical properties of red wine samples, along with their corresponding quality ratings.\n",
    "\n",
    "Your task is to apply machine learning techniques to build a model that can predict the quality of red wine based on its chemical attributes. By analyzing this dataset, you will gain hands-on experience in classification tasks and understand how different chemical components contribute to the overall quality of red wine.\n",
    "\n",
    "Throughout this assignment, you will be using Python and the scikit-learn library, which provides a wide range of machine learning algorithms and evaluation metrics. You will learn how to preprocess the data, split it into training and testing sets, train a classification model, make predictions, and evaluate the model's performance using various metrics.\n",
    "\n",
    "By the end of this assignment, you will have a solid understanding of the entire machine learning pipeline, from data preprocessing to model evaluation. You will also gain valuable insights into the factors influencing red wine quality.\n",
    "\n",
    "So, let's dive in and uncork the mysteries of red wine quality prediction using machine learning!\n",
    "\n",
    "The dataset can be found here: [Kaggle.com Red Wine Quality](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc35869",
   "metadata": {},
   "source": [
    "### 1. Load necessary data \n",
    "\n",
    "- Download the data from the link, move it to the right place on computer and load it with `read_csv`\n",
    "\n",
    "- Use `df.head()` and `df.describe()` to explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f2565d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.571875\n",
      "Precision: 0.5671001102000189\n",
      "Recall: 0.571875\n",
      "F1 Score: 0.5690568475452197\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  1  0  0]\n",
      " [ 0  1  5  3  1  0]\n",
      " [ 1  3 89 34  3  0]\n",
      " [ 0  3 37 72 18  2]\n",
      " [ 0  1  5 15 20  1]\n",
      " [ 0  0  1  1  2  1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.12      0.10      0.11        10\n",
      "           5       0.65      0.68      0.67       130\n",
      "           6       0.57      0.55      0.56       132\n",
      "           7       0.45      0.48      0.47        42\n",
      "           8       0.25      0.20      0.22         5\n",
      "\n",
      "    accuracy                           0.57       320\n",
      "   macro avg       0.34      0.33      0.34       320\n",
      "weighted avg       0.57      0.57      0.57       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "zip_path = r\"C:\\Users\\nayif\\py3b_nayef_omer\\week7\\archive.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    file_name = zip_ref.namelist()[0] \n",
    "    with zip_ref.open(file_name) as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "X = df.drop(\"quality\", axis=1)  \n",
    "y = df[\"quality\"]  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2052de",
   "metadata": {},
   "source": [
    "### 2. Prepare the data by extracting features and labels\n",
    "\n",
    "Extract features (`X`) and labels (`y`). You can do this in several ways, the following is an example:\n",
    "\n",
    "```python\n",
    "# This will exclude the 'quality' column from features and return the result\n",
    "# Save the result to a variable named X to extract the features\n",
    "df.drop('quality', axis=1)\n",
    "\n",
    "# This will extract the 'quality' column as the target variable and return the result\n",
    "# Save the result to a variable named y to extract the labels\n",
    "df['quality']  \n",
    "```\n",
    "\n",
    "To validate your results you can use `print` tou output `X.shape` and `y.shape` and you should get this result:\n",
    "\n",
    "```\n",
    "Shape of features (X): (1599, 11)\n",
    "Shape of labels (y): (1599,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b615829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (X): (1599, 11)\n",
      "Shape of labels (y): (1599,)\n",
      "Accuracy: 0.58125\n",
      "Precision: 0.5809558344680599\n",
      "Recall: 0.58125\n",
      "F1 Score: 0.5809429199878732\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  1  0  0]\n",
      " [ 0  0  4  5  1  0]\n",
      " [ 1  5 89 33  2  0]\n",
      " [ 0  3 36 74 17  2]\n",
      " [ 0  2  3 13 22  2]\n",
      " [ 0  0  1  1  2  1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.67      0.68      0.68       130\n",
      "           6       0.58      0.56      0.57       132\n",
      "           7       0.50      0.52      0.51        42\n",
      "           8       0.20      0.20      0.20         5\n",
      "\n",
      "    accuracy                           0.58       320\n",
      "   macro avg       0.33      0.33      0.33       320\n",
      "weighted avg       0.58      0.58      0.58       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "zip_path = r\"C:\\Users\\nayif\\py3b_nayef_omer\\week7\\archive.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    file_name = zip_ref.namelist()[0]  \n",
    "    with zip_ref.open(file_name) as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "X = df.drop('quality', axis=1)  \n",
    "y = df['quality']  \n",
    "\n",
    "print(\"Shape of features (X):\", X.shape)\n",
    "print(\"Shape of labels (y):\", y.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02497fd4",
   "metadata": {},
   "source": [
    "### 3. Split data into training and testing sets\n",
    "\n",
    "Use `train_test_split` as I did in my example. Save the result to the variables `X_train, X_test, y_train, y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff63d9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (X): (1599, 11)\n",
      "Shape of labels (y): (1599,)\n",
      "Shape of training features (X_train): (1279, 11)\n",
      "Shape of testing features (X_test): (320, 11)\n",
      "Shape of training labels (y_train): (1279,)\n",
      "Shape of testing labels (y_test): (320,)\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "zip_path = r\"C:\\Users\\nayif\\py3b_nayef_omer\\week7\\archive.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    file_name = zip_ref.namelist()[0]  \n",
    "    with zip_ref.open(file_name) as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "X = df.drop('quality', axis=1)  \n",
    "y = df['quality']  \n",
    "\n",
    "print(\"Shape of features (X):\", X.shape)\n",
    "print(\"Shape of labels (y):\", y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Shape of training features (X_train):\", X_train_scaled.shape)\n",
    "print(\"Shape of testing features (X_test):\", X_test_scaled.shape)\n",
    "print(\"Shape of training labels (y_train):\", y_train.shape)\n",
    "print(\"Shape of testing labels (y_test):\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d1453",
   "metadata": {},
   "source": [
    "### 4. Create an instance of the DecisionTreeRegressor class and fit the model to the training data\n",
    "\n",
    "Use other models as well such as Support Vector Classifier (SVC) and K-Nearest Neighbors Classifier (KNN)\n",
    "\n",
    "To create an instance to train and predict, you just call its constructor and save it to a variable with a fitting name. In my example I used `clf = DecisionTreeClassifier()`. Do the same with the following:\n",
    "\n",
    "- `DecisionTreeRegressor()`\n",
    "- `SVC()`\n",
    "- `KNeighborsClassifier()`\n",
    "\n",
    "After that, use the `fit`function to train your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f9f2c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor Evaluation:\n",
      "Accuracy: 0.596875\n",
      "Precision: 0.5942776051170925\n",
      "Recall: 0.596875\n",
      "F1 Score: 0.5952138672156423\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  1  0  0]\n",
      " [ 0  1  5  4  0  0]\n",
      " [ 2  2 91 31  4  0]\n",
      " [ 2  3 30 80 16  1]\n",
      " [ 0  0  2 19 19  2]\n",
      " [ 0  0  0  2  3  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.17      0.10      0.12        10\n",
      "           5       0.71      0.70      0.71       130\n",
      "           6       0.58      0.61      0.59       132\n",
      "           7       0.45      0.45      0.45        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.60       320\n",
      "   macro avg       0.32      0.31      0.31       320\n",
      "weighted avg       0.59      0.60      0.60       320\n",
      "\n",
      "\n",
      "Support Vector Classifier Evaluation:\n",
      "Accuracy: 0.603125\n",
      "Precision: 0.5690995065789475\n",
      "Recall: 0.603125\n",
      "F1 Score: 0.5728911344073244\n",
      "Confusion Matrix:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  8  2  0  0]\n",
      " [ 0  0 99 31  0  0]\n",
      " [ 0  0 43 85  4  0]\n",
      " [ 0  0  1 32  9  0]\n",
      " [ 0  0  0  2  3  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.65      0.76      0.70       130\n",
      "           6       0.56      0.64      0.60       132\n",
      "           7       0.56      0.21      0.31        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.60       320\n",
      "   macro avg       0.30      0.27      0.27       320\n",
      "weighted avg       0.57      0.60      0.57       320\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Classifier Evaluation:\n",
      "Accuracy: 0.546875\n",
      "Precision: 0.5223882430488974\n",
      "Recall: 0.546875\n",
      "F1 Score: 0.5309047543748682\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  1  0  0]\n",
      " [ 0  0  4  6  0  0]\n",
      " [ 0  2 88 40  0  0]\n",
      " [ 1  0 49 72 10  0]\n",
      " [ 0  0  7 20 15  0]\n",
      " [ 0  0  1  1  3  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.59      0.68      0.63       130\n",
      "           6       0.51      0.55      0.53       132\n",
      "           7       0.54      0.36      0.43        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.55       320\n",
      "   macro avg       0.27      0.26      0.26       320\n",
      "weighted avg       0.52      0.55      0.53       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "zip_path = r\"C:\\Users\\nayif\\py3b_nayef_omer\\week7\\archive.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    file_name = zip_ref.namelist()[0] \n",
    "    with zip_ref.open(file_name) as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "X = df.drop('quality', axis=1) \n",
    "y = df['quality']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "svc_classifier = SVC()\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "dt_regressor.fit(X_train_scaled, y_train)\n",
    "svc_classifier.fit(X_train_scaled, y_train)\n",
    "knn_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_dt = dt_regressor.predict(X_test_scaled)\n",
    "y_pred_svc = svc_classifier.predict(X_test_scaled)\n",
    "y_pred_knn = knn_classifier.predict(X_test_scaled)\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, cm, report\n",
    "\n",
    "accuracy_dt, precision_dt, recall_dt, f1_dt, cm_dt, report_dt = evaluate_model(y_test, y_pred_dt)\n",
    "\n",
    "accuracy_svc, precision_svc, recall_svc, f1_svc, cm_svc, report_svc = evaluate_model(y_test, y_pred_svc)\n",
    "\n",
    "accuracy_knn, precision_knn, recall_knn, f1_knn, cm_knn, report_knn = evaluate_model(y_test, y_pred_knn)\n",
    "\n",
    "print(\"Decision Tree Regressor Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_dt}\")\n",
    "print(f\"Precision: {precision_dt}\")\n",
    "print(f\"Recall: {recall_dt}\")\n",
    "print(f\"F1 Score: {f1_dt}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_dt)\n",
    "print(\"Classification Report:\")\n",
    "print(report_dt)\n",
    "\n",
    "print(\"\\nSupport Vector Classifier Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_svc}\")\n",
    "print(f\"Precision: {precision_svc}\")\n",
    "print(f\"Recall: {recall_svc}\")\n",
    "print(f\"F1 Score: {f1_svc}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_svc)\n",
    "print(\"Classification Report:\")\n",
    "print(report_svc)\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Classifier Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_knn}\")\n",
    "print(f\"Precision: {precision_knn}\")\n",
    "print(f\"Recall: {recall_knn}\")\n",
    "print(f\"F1 Score: {f1_knn}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_knn)\n",
    "print(\"Classification Report:\")\n",
    "print(report_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f90ee4",
   "metadata": {},
   "source": [
    "### 5. Make predictions on the testing set\n",
    "\n",
    "Use `predict` on the text data to make predictions on data that wasn't in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72f4e85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor - Mean Absolute Error: 0.478125\n",
      "Support Vector Classifier - Accuracy: 0.603125\n",
      "K-Nearest Neighbors Classifier - Accuracy: 0.553125\n",
      "\n",
      "Predictions using Decision Tree Regressor:\n",
      "[6. 5. 6. 5. 6. 5. 5. 5. 7. 6. 7. 6. 6. 5. 6. 6. 5. 6. 7. 5. 5. 6. 4. 6.\n",
      " 5. 6. 6. 5. 5. 6. 5. 5. 6. 6. 6. 5. 6. 6. 5. 6. 3. 6. 6. 5. 5. 5. 6. 6.\n",
      " 5. 6. 5. 5. 6. 7. 5. 6. 6. 6. 5. 5. 5. 7. 6. 6. 6. 5. 7. 6. 6. 6. 6. 5.\n",
      " 6. 6. 6. 5. 6. 5. 5. 7. 5. 7. 5. 6. 7. 6. 5. 6. 6. 6. 7. 6. 5. 5. 5. 6.\n",
      " 5. 6. 5. 5. 4. 5. 6. 7. 5. 7. 6. 5. 6. 5. 6. 5. 6. 5. 5. 6. 5. 5. 5. 6.\n",
      " 6. 6. 6. 6. 6. 5. 7. 5. 5. 6. 6. 6. 4. 6. 6. 5. 5. 6. 5. 5. 7. 8. 7. 6.\n",
      " 5. 5. 4. 6. 5. 5. 6. 6. 6. 5. 6. 5. 6. 7. 5. 6. 6. 5. 6. 5. 5. 5. 6. 5.\n",
      " 5. 6. 5. 5. 7. 5. 7. 6. 6. 5. 5. 6. 5. 5. 5. 6. 4. 6. 6. 6. 7. 5. 5. 7.\n",
      " 5. 6. 6. 5. 5. 6. 5. 7. 5. 6. 6. 5. 6. 5. 5. 3. 7. 5. 8. 5. 5. 8. 7. 6.\n",
      " 6. 5. 6. 5. 5. 6. 6. 5. 4. 6. 6. 7. 6. 6. 5. 5. 7. 6. 5. 7. 5. 7. 6. 5.\n",
      " 6. 6. 5. 7. 6. 7. 6. 6. 8. 5. 6. 6. 5. 6. 7. 5. 5. 6. 6. 6. 7. 5. 5. 6.\n",
      " 6. 6. 6. 6. 6. 6. 5. 6. 6. 6. 6. 5. 5. 8. 7. 6. 7. 5. 6. 6. 5. 7. 5. 8.\n",
      " 6. 6. 5. 7. 8. 6. 5. 6. 5. 7. 6. 6. 5. 5. 6. 3. 6. 5. 4. 6. 5. 7. 5. 5.\n",
      " 5. 6. 6. 6. 5. 5. 6. 5.]\n",
      "\n",
      "Predictions using Support Vector Classifier:\n",
      "[5 5 6 5 6 5 5 5 6 6 6 5 6 5 5 6 5 6 7 5 5 5 6 6 5 5 6 5 5 6 5 5 6 5 6 5 6\n",
      " 6 6 6 6 5 6 5 6 6 6 6 5 6 5 5 6 7 5 5 6 5 6 5 6 6 5 5 6 5 6 5 7 5 6 5 6 6\n",
      " 6 5 7 5 6 7 5 7 5 5 6 6 5 6 6 5 6 5 5 6 5 6 5 6 5 5 5 5 6 6 6 6 6 5 6 5 6\n",
      " 5 6 5 6 6 6 5 5 6 6 6 6 5 5 5 6 6 5 6 6 5 5 6 6 5 5 5 5 6 6 6 6 5 6 5 6 5\n",
      " 6 5 6 6 5 6 6 6 5 6 5 6 6 6 6 5 5 6 5 5 5 5 5 5 6 5 7 6 6 5 5 5 5 6 5 7 5\n",
      " 6 6 6 7 5 6 6 5 6 6 5 5 5 6 6 5 5 5 5 7 6 5 5 6 5 7 5 6 6 6 6 6 5 6 5 5 6\n",
      " 6 6 5 5 5 7 5 5 5 5 6 6 5 6 5 6 6 5 5 5 6 6 5 6 6 5 6 5 6 5 5 6 5 5 5 6 6\n",
      " 6 6 6 5 7 6 6 5 5 6 6 5 6 5 5 6 5 6 6 6 5 7 5 5 5 5 6 5 6 5 6 5 7 6 5 5 6\n",
      " 5 6 6 6 5 5 6 5 5 5 6 6 6 7 6 6 6 6 5 6 5 5 6 5]\n",
      "\n",
      "Predictions using K-Nearest Neighbors Classifier:\n",
      "[5 5 6 6 6 5 5 5 6 6 7 6 6 5 5 7 5 5 7 5 4 6 5 6 5 6 6 6 5 6 5 5 5 5 5 5 6\n",
      " 6 5 6 6 5 6 5 6 6 7 6 5 5 5 5 6 7 5 5 6 5 6 5 6 5 5 5 7 5 6 6 7 5 6 6 6 5\n",
      " 6 5 7 5 6 7 5 7 5 5 6 6 5 6 7 6 6 5 5 6 5 5 5 6 5 6 6 5 6 6 6 6 6 5 5 5 7\n",
      " 5 6 5 5 6 5 5 5 6 6 5 6 5 6 6 6 5 5 5 6 5 5 6 5 5 5 5 5 6 6 6 5 6 6 5 5 3\n",
      " 6 5 6 6 5 5 6 6 5 5 5 6 5 6 6 5 5 6 5 5 5 5 5 5 5 6 5 6 6 5 6 5 4 7 6 7 5\n",
      " 6 6 6 7 6 6 6 5 6 6 5 5 6 5 6 6 5 5 5 6 6 5 5 5 5 7 5 6 6 6 7 6 5 6 6 6 6\n",
      " 7 6 6 5 6 7 6 5 6 4 6 6 5 6 5 6 6 5 6 5 6 6 5 5 5 5 6 5 5 5 6 5 5 5 5 5 5\n",
      " 7 7 6 5 7 6 7 6 5 5 6 5 6 5 6 6 5 6 6 6 6 7 6 5 5 5 6 5 6 6 6 5 6 5 6 5 6\n",
      " 5 7 6 7 6 5 6 5 6 5 6 6 6 7 6 5 6 5 5 6 5 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "\n",
    "zip_path = r\"C:\\Users\\nayif\\py3b_nayef_omer\\week7\\archive.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    file_name = zip_ref.namelist()[0] \n",
    "    with zip_ref.open(file_name) as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "X = df.drop(\"quality\", axis=1)  \n",
    "y = df[\"quality\"]  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "svc_classifier = SVC()\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "dt_regressor.fit(X_train, y_train)\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_regressor.predict(X_test)\n",
    "y_pred_svc = svc_classifier.predict(X_test)\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "dt_mae = mean_absolute_error(y_test, y_pred_dt)\n",
    "\n",
    "svc_accuracy = accuracy_score(y_test, y_pred_svc)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"Decision Tree Regressor - Mean Absolute Error:\", dt_mae)\n",
    "print(\"Support Vector Classifier - Accuracy:\", svc_accuracy)\n",
    "print(\"K-Nearest Neighbors Classifier - Accuracy:\", knn_accuracy)\n",
    "\n",
    "print(\"\\nPredictions using Decision Tree Regressor:\")\n",
    "print(y_pred_dt)\n",
    "\n",
    "print(\"\\nPredictions using Support Vector Classifier:\")\n",
    "print(y_pred_svc)\n",
    "\n",
    "print(\"\\nPredictions using K-Nearest Neighbors Classifier:\")\n",
    "print(y_pred_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46a74a",
   "metadata": {},
   "source": [
    "### 6. Evaluate the performance of the model \n",
    "\n",
    "Use accuracy, precision, recall, and F1 score and do the same with your other models to compare them.\n",
    "\n",
    "Follow my example to calculate metrics such as `accuracy`, `precision`, `recall`, and `f1_score` for all three of your models.\n",
    "\n",
    "Print your results to compare the models. Which one performed best? Is any of the models suitable for predicting the wine quality?\n",
    "\n",
    "> You may get this error `UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples`. This indicates that there are certain labels in the test set that have no predicted samples, leading to undefined precision values for those labels. To handle this warning, you can set the zero_division parameter to control the behavior when encountering such cases. Add the parameter `zero_division=1` to your `precision_score` function calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9da4898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor - Accuracy: 0.63125\n",
      "Decision Tree Regressor - Precision: 0.6338511787589052\n",
      "Decision Tree Regressor - Recall: 0.63125\n",
      "Decision Tree Regressor - F1 Score: 0.6318375793273511\n",
      "\n",
      "Support Vector Classifier - Accuracy: 0.603125\n",
      "Support Vector Classifier - Precision: 0.6190995065789474\n",
      "Support Vector Classifier - Recall: 0.603125\n",
      "Support Vector Classifier - F1 Score: 0.5728911344073244\n",
      "\n",
      "K-Nearest Neighbors Classifier - Accuracy: 0.553125\n",
      "K-Nearest Neighbors Classifier - Precision: 0.5524217743823907\n",
      "K-Nearest Neighbors Classifier - Recall: 0.553125\n",
      "K-Nearest Neighbors Classifier - F1 Score: 0.5391265328874024\n",
      "\n",
      "Classification Report for Decision Tree Regressor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.12      0.10      0.11        10\n",
      "           5       0.74      0.72      0.73       130\n",
      "           6       0.62      0.66      0.64       132\n",
      "           7       0.56      0.48      0.51        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.63       320\n",
      "   macro avg       0.34      0.33      0.33       320\n",
      "weighted avg       0.63      0.63      0.63       320\n",
      "\n",
      "\n",
      "Classification Report for Support Vector Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.65      0.76      0.70       130\n",
      "           6       0.56      0.64      0.60       132\n",
      "           7       0.56      0.21      0.31        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.60       320\n",
      "   macro avg       0.30      0.27      0.27       320\n",
      "weighted avg       0.57      0.60      0.57       320\n",
      "\n",
      "\n",
      "Classification Report for K-Nearest Neighbors Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.33      0.10      0.15        10\n",
      "           5       0.60      0.68      0.64       130\n",
      "           6       0.52      0.56      0.54       132\n",
      "           7       0.52      0.33      0.41        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.55       320\n",
      "   macro avg       0.33      0.28      0.29       320\n",
      "weighted avg       0.54      0.55      0.54       320\n",
      "\n",
      "\n",
      "The best performing model based on F1 score is: Decision Tree Regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\nayif\\.conda\\envs\\myenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "zip_path = r\"C:\\Users\\nayif\\py3b_nayef_omer\\week7\\archive.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    file_name = zip_ref.namelist()[0]  \n",
    "    with zip_ref.open(file_name) as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "X = df.drop(\"quality\", axis=1)  \n",
    "y = df[\"quality\"]  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "svc_classifier = SVC()\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "dt_regressor.fit(X_train, y_train)\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_regressor.predict(X_test)\n",
    "y_pred_svc = svc_classifier.predict(X_test)\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_dt_class = y_pred_dt.round().astype(int)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt_class)\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "precision_dt = precision_score(y_test, y_pred_dt_class, average='weighted', zero_division=1)\n",
    "precision_svc = precision_score(y_test, y_pred_svc, average='weighted', zero_division=1)\n",
    "precision_knn = precision_score(y_test, y_pred_knn, average='weighted', zero_division=1)\n",
    "\n",
    "recall_dt = recall_score(y_test, y_pred_dt_class, average='weighted', zero_division=1)\n",
    "recall_svc = recall_score(y_test, y_pred_svc, average='weighted', zero_division=1)\n",
    "recall_knn = recall_score(y_test, y_pred_knn, average='weighted', zero_division=1)\n",
    "\n",
    "f1_dt = f1_score(y_test, y_pred_dt_class, average='weighted', zero_division=1)\n",
    "f1_svc = f1_score(y_test, y_pred_svc, average='weighted', zero_division=1)\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted', zero_division=1)\n",
    "\n",
    "print(\"Decision Tree Regressor - Accuracy:\", accuracy_dt)\n",
    "print(\"Decision Tree Regressor - Precision:\", precision_dt)\n",
    "print(\"Decision Tree Regressor - Recall:\", recall_dt)\n",
    "print(\"Decision Tree Regressor - F1 Score:\", f1_dt)\n",
    "\n",
    "print(\"\\nSupport Vector Classifier - Accuracy:\", accuracy_svc)\n",
    "print(\"Support Vector Classifier - Precision:\", precision_svc)\n",
    "print(\"Support Vector Classifier - Recall:\", recall_svc)\n",
    "print(\"Support Vector Classifier - F1 Score:\", f1_svc)\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Classifier - Accuracy:\", accuracy_knn)\n",
    "print(\"K-Nearest Neighbors Classifier - Precision:\", precision_knn)\n",
    "print(\"K-Nearest Neighbors Classifier - Recall:\", recall_knn)\n",
    "print(\"K-Nearest Neighbors Classifier - F1 Score:\", f1_knn)\n",
    "\n",
    "print(\"\\nClassification Report for Decision Tree Regressor:\")\n",
    "print(classification_report(y_test, y_pred_dt_class))\n",
    "\n",
    "print(\"\\nClassification Report for Support Vector Classifier:\")\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "\n",
    "print(\"\\nClassification Report for K-Nearest Neighbors Classifier:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "best_model = None\n",
    "if f1_dt > f1_svc and f1_dt > f1_knn:\n",
    "    best_model = \"Decision Tree Regressor\"\n",
    "elif f1_svc > f1_dt and f1_svc > f1_knn:\n",
    "    best_model = \"Support Vector Classifier\"\n",
    "else:\n",
    "    best_model = \"K-Nearest Neighbors Classifier\"\n",
    "\n",
    "print(\"\\nThe best performing model based on F1 score is:\", best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e435464",
   "metadata": {},
   "source": [
    "### 7. Other evaluation methods\n",
    "\n",
    "Use `confusion_matrix` and `classification_report` to evaluate further and compare your models\n",
    "\n",
    "> You may get the same error about *ill-defined Precision and F-score*. By adding the parameter `zero_division=1` to your `classification_report` calls.\n",
    "\n",
    "> When you add the parameter `zero_division=1` to the `classification_report` function calls, it controls the behavior for labels with no predicted samples. By setting `zero_division` to 1, the precision and F1 score for such labels will be assigned a value of 0 by default, instead of raising the `UndefinedMetricWarning` and setting the values to 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "820ee773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor - Accuracy: 0.625\n",
      "Decision Tree Regressor - Precision: 0.6222429901998912\n",
      "Decision Tree Regressor - Recall: 0.625\n",
      "Decision Tree Regressor - F1 Score: 0.6231422717360218\n",
      "\n",
      "Support Vector Classifier - Accuracy: 0.603125\n",
      "Support Vector Classifier - Precision: 0.6190995065789474\n",
      "Support Vector Classifier - Recall: 0.603125\n",
      "Support Vector Classifier - F1 Score: 0.5728911344073244\n",
      "\n",
      "K-Nearest Neighbors Classifier - Accuracy: 0.553125\n",
      "K-Nearest Neighbors Classifier - Precision: 0.5524217743823907\n",
      "K-Nearest Neighbors Classifier - Recall: 0.553125\n",
      "K-Nearest Neighbors Classifier - F1 Score: 0.5391265328874024\n",
      "\n",
      "Classification Report for Decision Tree Regressor:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.17      0.10      0.12        10\n",
      "           5       0.73      0.72      0.73       130\n",
      "           6       0.62      0.65      0.64       132\n",
      "           7       0.49      0.45      0.47        42\n",
      "           8       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.62       320\n",
      "   macro avg       0.33      0.32      0.33       320\n",
      "weighted avg       0.62      0.62      0.62       320\n",
      "\n",
      "\n",
      "Classification Report for Support Vector Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         1\n",
      "           4       1.00      0.00      0.00        10\n",
      "           5       0.65      0.76      0.70       130\n",
      "           6       0.56      0.64      0.60       132\n",
      "           7       0.56      0.21      0.31        42\n",
      "           8       1.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.60       320\n",
      "   macro avg       0.80      0.27      0.27       320\n",
      "weighted avg       0.62      0.60      0.57       320\n",
      "\n",
      "\n",
      "Classification Report for K-Nearest Neighbors Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.33      0.10      0.15        10\n",
      "           5       0.60      0.68      0.64       130\n",
      "           6       0.52      0.56      0.54       132\n",
      "           7       0.52      0.33      0.41        42\n",
      "           8       1.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.55       320\n",
      "   macro avg       0.50      0.28      0.29       320\n",
      "weighted avg       0.55      0.55      0.54       320\n",
      "\n",
      "\n",
      "Confusion Matrix for Decision Tree Regressor:\n",
      "[[ 0  0  0  1  0  0]\n",
      " [ 0  1  6  2  1  0]\n",
      " [ 2  3 94 29  2  0]\n",
      " [ 1  2 26 86 14  3]\n",
      " [ 0  0  3 18 19  2]\n",
      " [ 0  0  0  2  3  0]]\n",
      "\n",
      "Confusion Matrix for Support Vector Classifier:\n",
      "[[ 0  0  1  0  0  0]\n",
      " [ 0  0  8  2  0  0]\n",
      " [ 0  0 99 31  0  0]\n",
      " [ 0  0 43 85  4  0]\n",
      " [ 0  0  1 32  9  0]\n",
      " [ 0  0  0  2  3  0]]\n",
      "\n",
      "Confusion Matrix for K-Nearest Neighbors Classifier:\n",
      "[[ 0  0  0  1  0  0]\n",
      " [ 0  1  3  6  0  0]\n",
      " [ 0  2 88 40  0  0]\n",
      " [ 1  0 47 74 10  0]\n",
      " [ 0  0  7 21 14  0]\n",
      " [ 0  0  1  1  3  0]]\n",
      "\n",
      "The best performing model based on F1 score is: Decision Tree Regressor\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "zip_path = r\"C:\\Users\\nayif\\py3b_nayef_omer\\week7\\archive.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    file_name = zip_ref.namelist()[0]  \n",
    "    with zip_ref.open(file_name) as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "X = df.drop(\"quality\", axis=1) \n",
    "y = df[\"quality\"]  \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "svc_classifier = SVC()\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "dt_regressor.fit(X_train, y_train)\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_regressor.predict(X_test)\n",
    "y_pred_svc = svc_classifier.predict(X_test)\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "y_pred_dt_class = y_pred_dt.round().astype(int)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt_class)\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "precision_dt = precision_score(y_test, y_pred_dt_class, average='weighted', zero_division=1)\n",
    "precision_svc = precision_score(y_test, y_pred_svc, average='weighted', zero_division=1)\n",
    "precision_knn = precision_score(y_test, y_pred_knn, average='weighted', zero_division=1)\n",
    "\n",
    "recall_dt = recall_score(y_test, y_pred_dt_class, average='weighted', zero_division=1)\n",
    "recall_svc = recall_score(y_test, y_pred_svc, average='weighted', zero_division=1)\n",
    "recall_knn = recall_score(y_test, y_pred_knn, average='weighted', zero_division=1)\n",
    "\n",
    "f1_dt = f1_score(y_test, y_pred_dt_class, average='weighted', zero_division=1)\n",
    "f1_svc = f1_score(y_test, y_pred_svc, average='weighted', zero_division=1)\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='weighted', zero_division=1)\n",
    "\n",
    "print(\"Decision Tree Regressor - Accuracy:\", accuracy_dt)\n",
    "print(\"Decision Tree Regressor - Precision:\", precision_dt)\n",
    "print(\"Decision Tree Regressor - Recall:\", recall_dt)\n",
    "print(\"Decision Tree Regressor - F1 Score:\", f1_dt)\n",
    "\n",
    "print(\"\\nSupport Vector Classifier - Accuracy:\", accuracy_svc)\n",
    "print(\"Support Vector Classifier - Precision:\", precision_svc)\n",
    "print(\"Support Vector Classifier - Recall:\", recall_svc)\n",
    "print(\"Support Vector Classifier - F1 Score:\", f1_svc)\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Classifier - Accuracy:\", accuracy_knn)\n",
    "print(\"K-Nearest Neighbors Classifier - Precision:\", precision_knn)\n",
    "print(\"K-Nearest Neighbors Classifier - Recall:\", recall_knn)\n",
    "print(\"K-Nearest Neighbors Classifier - F1 Score:\", f1_knn)\n",
    "\n",
    "print(\"\\nClassification Report for Decision Tree Regressor:\")\n",
    "print(classification_report(y_test, y_pred_dt_class, zero_division=1))\n",
    "\n",
    "print(\"\\nClassification Report for Support Vector Classifier:\")\n",
    "print(classification_report(y_test, y_pred_svc, zero_division=1))\n",
    "\n",
    "print(\"\\nClassification Report for K-Nearest Neighbors Classifier:\")\n",
    "print(classification_report(y_test, y_pred_knn, zero_division=1))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Decision Tree Regressor:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt_class))\n",
    "\n",
    "print(\"\\nConfusion Matrix for Support Vector Classifier:\")\n",
    "print(confusion_matrix(y_test, y_pred_svc))\n",
    "\n",
    "print(\"\\nConfusion Matrix for K-Nearest Neighbors Classifier:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "best_model = None\n",
    "if f1_dt > f1_svc and f1_dt > f1_knn:\n",
    "    best_model = \"Decision Tree Regressor\"\n",
    "elif f1_svc > f1_dt and f1_svc > f1_knn:\n",
    "    best_model = \"Support Vector Classifier\"\n",
    "else:\n",
    "    best_model = \"K-Nearest Neighbors Classifier\"\n",
    "\n",
    "print(\"\\nThe best performing model based on F1 score is:\", best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49540271",
   "metadata": {},
   "source": [
    "## Complete!\n",
    "\n",
    "Submit your work by pushing the changes to Github, inviting the teacher/s to your repository and submitting ths link on ItsLearning under Assignment 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
